{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNU0L1WJMZHA3VqqYrJWPlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surya-moorthy/Mlops/blob/main/cifarImageClassifier_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, save\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms,ToTensor\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataset_train = CIFAR10(root=\"data\",download=True,train=True,transform=ToTensor())\n",
        "dataset = DataLoader(dataset_train,batch_size=32,shuffle=True)\n",
        "\n",
        "targets = dataset_train.targets\n",
        "num_of_classes = len(set(targets))\n",
        "\n",
        "images, labels = next(iter(dataset))\n",
        "\n",
        "print(images.shape)\n",
        "print(images[0].shape)\n",
        "\n",
        "class ClassImagesCifar(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ClassImagesCifar,self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=2,padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=1)\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=2,padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2,padding=1)\n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=2,padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2,padding=1)\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=2,padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2,stride=2,padding=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc6 = nn.Linear(4096,512)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.dropout7 = nn.Dropout(0.5)\n",
        "        self.fc7 = nn.Linear(512,256)\n",
        "        self.relu7 = nn.ReLU()\n",
        "        self.fc8 = nn.Linear(256,num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "\n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.maxpool3(out)\n",
        "\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.maxpool4(out)\n",
        "\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc6(out)\n",
        "        out = self.relu6(out)\n",
        "\n",
        "        out = self.dropout7(out)\n",
        "        out = self.fc7(out)\n",
        "        out = self.relu7(out)\n",
        "\n",
        "        out = self.fc8(out)\n",
        "        return out\n",
        "\n",
        "clf = ClassImagesCifar(num_of_classes).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(clf.parameters(),lr=0.0001)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for epoch in range(25):\n",
        "        for batch in dataset:\n",
        "            X, y = batch\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = clf(X)\n",
        "            loss = loss_func(output,y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch} has a loss of {loss}\")\n",
        "\n",
        "with open('model_compiled.pt',\"wb\") as f:\n",
        "    save(clf.state_dict(),f)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_OYed_wRyhy",
        "outputId": "1a3819e5-fe2c-4bcf-e2bd-52e635e9f175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 28.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "torch.Size([32, 3, 32, 32])\n",
            "torch.Size([3, 32, 32])\n",
            "Epoch 0 has a loss of 2.294776201248169\n",
            "Epoch 1 has a loss of 2.28483247756958\n",
            "Epoch 2 has a loss of 2.2948086261749268\n",
            "Epoch 3 has a loss of 2.305663585662842\n",
            "Epoch 4 has a loss of 2.3033711910247803\n",
            "Epoch 5 has a loss of 2.302550792694092\n",
            "Epoch 6 has a loss of 2.3014731407165527\n",
            "Epoch 7 has a loss of 2.3094286918640137\n",
            "Epoch 8 has a loss of 2.3060662746429443\n",
            "Epoch 9 has a loss of 2.293626308441162\n",
            "Epoch 10 has a loss of 2.3046398162841797\n",
            "Epoch 11 has a loss of 2.311518669128418\n",
            "Epoch 12 has a loss of 2.2993099689483643\n",
            "Epoch 13 has a loss of 2.303626298904419\n",
            "Epoch 14 has a loss of 2.298217296600342\n",
            "Epoch 15 has a loss of 2.3078815937042236\n",
            "Epoch 16 has a loss of 2.3015100955963135\n",
            "Epoch 17 has a loss of 2.300851345062256\n",
            "Epoch 18 has a loss of 2.3105242252349854\n",
            "Epoch 19 has a loss of 2.3006255626678467\n",
            "Epoch 20 has a loss of 2.306800365447998\n",
            "Epoch 21 has a loss of 2.2935922145843506\n",
            "Epoch 22 has a loss of 2.305905342102051\n",
            "Epoch 23 has a loss of 2.3072452545166016\n",
            "Epoch 24 has a loss of 2.3042612075805664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import load\n",
        "from PIL import Image\n",
        "print(targets)\n",
        "with open('model_compiled.pt',\"rb\") as f:\n",
        "        clf.load_state_dict(load(f))\n",
        "img = Image.open('bird6.png')\n",
        "img_tensor = ToTensor()(img).unsqueeze(0).to('cuda')\n",
        "print(torch.argmax(clf(img_tensor)))"
      ],
      "metadata": {
        "id": "vV80Gl4mUJuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b34372-3d9b-45f1-c0b1-a947f7ace8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
               "tensor(9, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-ec8d690f2337>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  clf.load_state_dict(load(f))\n"
          ]
        }
      ]
    }
  ]
}
